{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: transformers in c:\\programdata\\anaconda3\\lib\\site-packages (3.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2020.10.23)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (1.18.1)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (0.1.94)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (20.1)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (4.42.1)\n",
      "Requirement already satisfied: protobuf in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.11.4)\n",
      "Requirement already satisfied: sacremoses in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: tokenizers==0.9.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (0.9.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->transformers) (2.4.6)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->transformers) (1.14.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from protobuf->transformers) (45.2.0.post20200210)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: wikipedia in c:\\programdata\\anaconda3\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from wikipedia) (2.22.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (from wikipedia) (4.8.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.0.4)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4->wikipedia) (1.9.5)\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.6.0+cpu in c:\\programdata\\anaconda3\\lib\\site-packages (1.6.0+cpu)\n",
      "Requirement already satisfied: torchvision==0.7.0+cpu in c:\\programdata\\anaconda3\\lib\\site-packages (0.7.0+cpu)\n",
      "Requirement already satisfied: future in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==1.6.0+cpu) (0.18.2)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==1.6.0+cpu) (1.18.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision==0.7.0+cpu) (7.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install wikipedia\n",
    "!pip install torch==1.6.0+cpu torchvision==0.7.0+cpu -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import wikipedia as wiki\n",
    "import nltk\n",
    "import re\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki.set_lang(\"pt\")\n",
    "sent_tokenizer = nltk.data.load('tokenizers/punkt/portuguese.pickle')"
   ]
  },
  {
   "source": [
    "## Fazendo Download do SQuAD em Português\n",
    "\n",
    "Trata-se de uma tradução automática para o português pelo Google Tradutor do dataset SQuAD v1.1 em inglês feita pelo grupo Deep Learning Brasil. Vale lembrar que a mesma foi revisada.\n",
    "https://forum.ailab.unb.br/t/datasets-em-portugues/251/4\n",
    "\n",
    "Disponível em:\n",
    "https://drive.google.com/file/d/1Q0IaIlv2h2BC468MwUFmUST0EyN7gNkn\n",
    "\n",
    "Como a base é muito grande, gerou-se uma nova base de treino (a base de teste não foi reduzida) que corresponde à metade da base inicial. Ela ficará do diretório \"squad-pt-small\". \n",
    "A base original está em \"squad-pt\". "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Fazendo o download do script run_squad.py:\n",
    "\n",
    "O script da huggingface utilizado para fazer o fine tuning do modelo Bert na base SQuAD selecionada."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n100 34008  100 34008    0     0  97724      0 --:--:-- --:--:-- --:--:-- 98005\n"
     ]
    }
   ],
   "source": [
    "!curl -L -O https://raw.githubusercontent.com/huggingface/transformers/master/examples/question-answering/run_squad.py"
   ]
  },
  {
   "source": [
    "## Fazendo o download do bert pré-treinado PyTorch em português:\n",
    "\n",
    "Link do projeto da startup brasileira NeuralMind: https://github.com/neuralmind-ai/portuguese-bert"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n  0  387M    0 17037    0     0  15334      0  7:21:31  0:00:01  7:21:30 15334\n  0  387M    0 1903k    0     0   910k      0  0:07:15  0:00:02  0:07:13  910k\n  3  387M    3 12.4M    0     0  4121k      0  0:01:36  0:00:03  0:01:33 4121k\n  5  387M    5 21.5M    0     0  5399k      0  0:01:13  0:00:04  0:01:09 5399k\n  7  387M    7 27.7M    0     0  5565k      0  0:01:11  0:00:05  0:01:06 5793k\n  8  387M    8 32.2M    0     0  5413k      0  0:01:13  0:00:06  0:01:07 6617k\n  9  387M    9 36.8M    0     0  5319k      0  0:01:14  0:00:07  0:01:07 7161k\n 10  387M   10 41.8M    0     0  5300k      0  0:01:14  0:00:08  0:01:06 6030k\n 12  387M   12 47.1M    0     0  5302k      0  0:01:14  0:00:09  0:01:05 5222k\n 13  387M   13 52.1M    0     0  5292k      0  0:01:14  0:00:10  0:01:04 5011k\n 14  387M   14 57.1M    0     0  5272k      0  0:01:15  0:00:11  0:01:04 5099k\n 16  387M   16 62.2M    0     0  5274k      0  0:01:15  0:00:12  0:01:03 5210k\n 17  387M   17 67.6M    0     0  5289k      0  0:01:15  0:00:13  0:01:02 5271k\n 18  387M   18 72.6M    0     0  5279k      0  0:01:15  0:00:14  0:01:01 5239k\n 20  387M   20 77.8M    0     0  5278k      0  0:01:15  0:00:15  0:01:00 5251k\n 21  387M   21 83.2M    0     0  5297k      0  0:01:14  0:00:16  0:00:58 5354k\n 23  387M   23 89.1M    0     0  5339k      0  0:01:14  0:00:17  0:00:57 5495k\n 24  387M   24 95.0M    0     0  5382k      0  0:01:13  0:00:18  0:00:55 5626k\n 26  387M   26  101M    0     0  5443k      0  0:01:12  0:00:19  0:00:53 5902k\n 28  387M   28  108M    0     0  5540k      0  0:01:11  0:00:20  0:00:51 6333k\n 30  387M   30  116M    0     0  5672k      0  0:01:09  0:00:21  0:00:48 6878k\n 32  387M   32  125M    0     0  5839k      0  0:01:07  0:00:22  0:00:45 7550k\n 35  387M   35  136M    0     0  6033k      0  0:01:05  0:00:23  0:00:42 8386k\n 38  387M   38  147M    0     0  6280k      0  0:01:03  0:00:24  0:00:39 9481k\n 41  387M   41  161M    0     0  6583k      0  0:01:00  0:00:25  0:00:35 10.5M\n 45  387M   45  176M    0     0  6940k      0  0:00:57  0:00:26  0:00:31 12.0M\n 50  387M   50  194M    0     0  7358k      0  0:00:53  0:00:27  0:00:26 13.7M\n 55  387M   55  214M    0     0  7827k      0  0:00:50  0:00:28  0:00:22 15.7M\n 61  387M   61  237M    0     0  8373k      0  0:00:47  0:00:29  0:00:18 18.0M\n 65  387M   65  255M    0     0  8652k      0  0:00:45  0:00:30  0:00:15 18.3M\n 69  387M   69  268M    0     0  8834k      0  0:00:44  0:00:31  0:00:13 18.2M\n 71  387M   71  278M    0     0  8874k      0  0:00:44  0:00:32  0:00:12 16.6M\n 74  387M   74  288M    0     0  8930k      0  0:00:44  0:00:33  0:00:11 14.7M\n 77  387M   77  299M    0     0  8988k      0  0:00:44  0:00:34  0:00:10 12.2M\n 80  387M   80  310M    0     0  9057k      0  0:00:43  0:00:35  0:00:08 11.2M\n 83  387M   83  321M    0     0  9123k      0  0:00:43  0:00:36  0:00:07 10.6M\n 85  387M   85  333M    0     0  9194k      0  0:00:43  0:00:37  0:00:06 10.9M\n 88  387M   88  344M    0     0  9255k      0  0:00:42  0:00:38  0:00:04 11.1M\n 91  387M   91  355M    0     0  9319k      0  0:00:42  0:00:39  0:00:03 11.3M\n 94  387M   94  367M    0     0  9376k      0  0:00:42  0:00:40  0:00:02 11.3M\n 97  387M   97  378M    0     0  9437k      0  0:00:42  0:00:41  0:00:01 11.4M\n100  387M  100  387M    0     0  9476k      0  0:00:41  0:00:41 --:--:-- 11.3M\n"
     ]
    }
   ],
   "source": [
    "!curl -L -O https://neuralmind-ai.s3.us-east-2.amazonaws.com/nlp/bert-base-portuguese-cased/bert-base-portuguese-cased_pytorch_checkpoint.zip"
   ]
  },
  {
   "source": [
    "## Fine-tuning do modelo BERT no dataset SQuAD em português\n",
    "\n",
    "Deve-se rodar os script run_squad.sh (para a base original) e run_squad_small.sh (para a base reduzida).\n",
    "Optou-se por roda diretamente do terminal, por fora do notebook para que as saídas fossem melhor visualizadas."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!run_squad.sh\n",
    "#!run_squad_small.sh"
   ]
  },
  {
   "source": [
    "Na máquina local dotada de processador i7-4790k e 16GB de RAM DDR4:\n",
    "\n",
    "* O run_squad.sh levou 122 horas para rodar e gastou até 15GB de RAM. \n",
    "* O run_squad_small.sh levou metade do tempo 61 horas e gastou um pouco mais de 10GB de RAM.\n",
    "\n",
    "Em relação aos resultados, disponíveis, obteve-se:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Results: {\n",
    "\t'exact': 67.06717123935667, \n",
    "\t'f1': 79.90285515400765, \n",
    "\t'total': 10570, \n",
    "\t'HasAns_exact': 67.06717123935667, \n",
    "\t'HasAns_f1': 79.90285515400765, \n",
    "\t'HasAns_total': 10570, \n",
    "\t'best_exact': 67.06717123935667, \n",
    "\t'best_exact_thresh': 0.0, \n",
    "\t'best_f1': 79.90285515400765, \n",
    "\t'best_f1_thresh': 0.0\n",
    "}\n",
    "\n",
    "ResultsSmall: {\n",
    "\t'exact': 64.91012298959319, \n",
    "\t'f1': 78.2144844407032, \n",
    "\t'total': 10570, \n",
    "\t'HasAns_exact': 64.91012298959319, \n",
    "\t'HasAns_f1': 78.2144844407032, \n",
    "\t'HasAns_total': 10570, \n",
    "\t'best_exact': 64.91012298959319, \n",
    "\t'best_exact_thresh': 0.0, \n",
    "\t'best_f1': 78.2144844407032, \n",
    "\t'best_f1_thresh': 0.0\n",
    "}"
   ]
  },
  {
   "source": [
    "O score F1-score é calculado como a média da métrica de similaridade usando F1-score entre cada resposta prevista e cada resposta real utilizando ambas como conjuntos de tokens. \n",
    "\n",
    "Observa-se que as métricas foram bem parecidas em ambas as bases. Mesmo com a base reduzida, os resultados foram satisfatórios (com 64.9% de respostas exatas e F1 de 78.2%). Para a base completa, o resultado foi de 67% de respostas exatas e 79.9% de F1-score."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Carregando o modelo pré-treinado"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"./squad-pt-saida/\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"./squad-pt-saida/\")"
   ]
  },
  {
   "source": [
    "## Testando o modelo com um exemplo da wikipedia\n",
    "\n",
    "Disponível em: https://pt.wikipedia.org/wiki/Brasil"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtemResposta(model, tokenizer, pergunta, contexto):\n",
    "    # Gera entrada do modelo:\n",
    "    inputs = tokenizer.encode_plus(pergunta, contexto, return_tensors=\"pt\") \n",
    "\n",
    "    # Obtém os scores:\n",
    "    resposta_inicio_scores, resposta_fim_scores = model(**inputs)\n",
    "    resposta_inicio = torch.argmax(resposta_inicio_scores)\n",
    "    resposta_fim = torch.argmax(resposta_fim_scores) + 1\n",
    "\n",
    "    # Obtém a melhor resposta:\n",
    "    return tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][resposta_inicio:resposta_fim]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexto = \"O território que atualmente forma o Brasil foi oficialmente descoberto pelos portugueses em 22 de abril de 1500, em expedição liderada por Pedro Álvares Cabral. O vínculo colonial foi rompido, de fato, quando em 1808 a capital do reino foi transferida de Lisboa para a cidade do Rio de Janeiro, depois de tropas francesas comandadas por Napoleão Bonaparte invadirem o território português. Em 1815, o Brasil se torna parte de um reino unido com Portugal. Dom Pedro I, o primeiro imperador, proclamou a independência política do país em 1822.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dom pedro i\n"
     ]
    }
   ],
   "source": [
    "pergunta1 = \"Quem proclamou a independência do Brasil?\"\n",
    "print(obtemResposta(model, tokenizer, pergunta1, contexto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "portugueses\n"
     ]
    }
   ],
   "source": [
    "pergunta2 = \"Quem descobriu o Brasil?\"\n",
    "print(obtemResposta(model, tokenizer, pergunta2, contexto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "22 de abril de 1500\n"
     ]
    }
   ],
   "source": [
    "pergunta3 = \"Quando o Brasil foi descoberto?\"\n",
    "print(obtemResposta(model, tokenizer, pergunta3, contexto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1808\n"
     ]
    }
   ],
   "source": [
    "pergunta4 = \"Quando o vínculo colonial foi rompido?\"\n",
    "print(obtemResposta(model, tokenizer, pergunta4, contexto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cidade do rio de janeiro\n"
     ]
    }
   ],
   "source": [
    "pergunta5 = \"Para onde a capital portuguesa foi transferida?\"\n",
    "print(obtemResposta(model, tokenizer, pergunta5, contexto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "lisboa\n"
     ]
    }
   ],
   "source": [
    "pergunta6 = \"Qual era a capital portuguesa antes de ser transferida?\"\n",
    "print(obtemResposta(model, tokenizer, pergunta6, contexto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pedro alvares cabral\n"
     ]
    }
   ],
   "source": [
    "pergunta7 = \"Quem comandou a viagem que encontrou o brasil?\"\n",
    "print(obtemResposta(model, tokenizer, pergunta7, contexto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pedro alvares cabral\n"
     ]
    }
   ],
   "source": [
    "pergunta8 = \"Qual o nome da pessoa responsável pelo grupo de pessoas que encontrou o Brasil?\"\n",
    "print(obtemResposta(model, tokenizer, pergunta8, contexto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "brasil se torna parte de um reino unido com portugal\n"
     ]
    }
   ],
   "source": [
    "pergunta9 = \"O que aconteceu em 1815?\"\n",
    "print(obtemResposta(model, tokenizer, pergunta9, contexto))"
   ]
  },
  {
   "source": [
    "## Criando um modelo de perguntas e respostas com buscas na wikipedia\n",
    "\n",
    "Baseado no trabalho de Pravesh Bisaria.\n",
    "\n",
    "Disponível em: https://qa.fastforwardlabs.com/pytorch/hugging%20face/wikipedia/bert/transformers/2020/05/19/Getting_Started_with_QA.html"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RespondedorPerguntas:\n",
    "    def __init__(self, pretrained_model_path='squad-pt-saida'):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(pretrained_model_path)\n",
    "        self.model = AutoModelForQuestionAnswering.from_pretrained(pretrained_model_path)\n",
    "        self.max_len = self.model.config.max_position_embeddings\n",
    "     \n",
    "    '''\n",
    "    Realiza tokenizacao retornando uma lista de chunks\n",
    "    '''\n",
    "    def __tokenize(self, pergunta, contexto):\n",
    "        inputs = self.tokenizer.encode_plus(pergunta, contexto, add_special_tokens=True, return_tensors=\"pt\")\n",
    "\n",
    "        # Caso o input seja grande demais para o modelo (mais de 512 caracteres)\n",
    "        if len(inputs[\"input_ids\"].tolist()[0]) > self.max_len:\n",
    "            inputs = self.__chunkify(inputs)\n",
    "        else:\n",
    "            inputs = [inputs]\n",
    "\n",
    "        return inputs\n",
    "\n",
    "    '''\n",
    "    Realiza chunkfy\n",
    "    '''\n",
    "    def __chunkify(self, inputs):\n",
    "        # Cria máscara de pergunta (0 é pergunta e 1 é contexto)\n",
    "        mascara_pergunta = inputs['token_type_ids'].lt(1)\n",
    "        pergunta = torch.masked_select(inputs['input_ids'], mascara_pergunta)\n",
    "\n",
    "        # Tamanho do chunk considerando já o token final [SEP]\n",
    "        tamanho_chunk = self.max_len - pergunta.size()[0] - 1 \n",
    "\n",
    "        # Cria dict de dict que será povoado com cada chunk de contexto:\n",
    "        chunked_input = OrderedDict()\n",
    "        for k,v in inputs.items():\n",
    "            # Separa pergunta e contexto:\n",
    "            pergunta = torch.masked_select(v, mascara_pergunta)\n",
    "            contexto = torch.masked_select(v, ~mascara_pergunta)\n",
    "            # Faz o split do contexto e itera sobre eles:\n",
    "            chunks = torch.split(contexto, tamanho_chunk)\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                # Concatena pergunta e contexto:\n",
    "                elem = torch.cat((pergunta, chunk))\n",
    "                # Apenas se não for o último chunk\n",
    "                if i != len(chunks)-1:\n",
    "                    if k == 'input_ids':\n",
    "                        # Concatena id de token final SEP\n",
    "                        elem = torch.cat((elem, torch.tensor([102])))\n",
    "                    else:\n",
    "                        # Concatena 1 para contexto\n",
    "                        elem = torch.cat((elem, torch.tensor([1])))\n",
    "\n",
    "                if i not in chunked_input:\n",
    "                    chunked_input[i] = {}\n",
    "                # Gera tensor linha:\n",
    "                chunked_input[i][k] = torch.unsqueeze(elem, dim=0)\n",
    "        return list(chunked_input.values())\n",
    "\n",
    "    '''\n",
    "    Obtém a resposta de uma pergunta dada um contexto com o score ideal:\n",
    "    '''\n",
    "    def __obtem_resposta(self, chunk):\n",
    "        # Obtém os scores:\n",
    "        resposta_inicio_scores, resposta_fim_scores = self.model(**chunk)\n",
    "        resposta_inicio = torch.argmax(resposta_inicio_scores)\n",
    "        resposta_fim = torch.argmax(resposta_fim_scores) + 1\n",
    "        resposta = self.tokenizer.convert_tokens_to_string(self.tokenizer.convert_ids_to_tokens(chunk[\"input_ids\"][0][resposta_inicio:resposta_fim]))\n",
    "\n",
    "        # Obtém a melhor resposta:\n",
    "        return float(torch.max(resposta_inicio_scores)), float(torch.max(resposta_fim_scores)), resposta\n",
    "\n",
    "    '''\n",
    "    Busca páginas da Wikipedia\n",
    "    TODO: Melhorar busca na wikipedia\n",
    "    '''\n",
    "    def __buscaPaginas(self, pergunta, results=5):\n",
    "        return [wiki.page(p) for p in wiki.search(pergunta, results)]\n",
    "\n",
    "    '''\n",
    "    Obtém resposta das N melhores respostas juntamente com as P páginas relacionadas:\n",
    "    '''\n",
    "    def obtem_respostas(self, pergunta, numero_paginas=5, top=5, debug=False):\n",
    "        paginas = self.__buscaPaginas(pergunta, numero_paginas)\n",
    "        respostas = []\n",
    "        for ordem_pagina, pagina in enumerate(paginas):\n",
    "            chunks = self.__tokenize(pergunta, pagina.content)\n",
    "            if debug:\n",
    "                print(f\"Buscando resposta na página: {pagina.title} - {len(chunks)} trechos de texto\")\n",
    "            for chunk in chunks:\n",
    "                r = self.__obtem_resposta(chunk)\n",
    "                if r[2] and r[2] != '[CLS]':\n",
    "                    # Calcula score pela fórmula (score_inicio + score_fim) * (numero_paginas - ordem_pagina):\n",
    "                    respostas.append(tuple([pagina.title, (r[0]+r[1])*(numero_paginas-ordem_pagina), r[2]]))\n",
    "            if debug:\n",
    "                print(f\"Número de respostas identificadas: {len(respostas)}\")\n",
    "\n",
    "        # Obtém as Top N respostas ordenadas:\n",
    "        return sorted(respostas, key=lambda tup: tup[1], reverse=True)[0:top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "respondedor = RespondedorPerguntas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Buscando resposta na página: Neymar - 43 trechos de texto\n",
      "Número de respostas identificadas: 4\n",
      "Buscando resposta na página: Mauricio de Sousa - 8 trechos de texto\n",
      "Número de respostas identificadas: 5\n",
      "Buscando resposta na página: Vila Mimosa - 4 trechos de texto\n",
      "Número de respostas identificadas: 6\n",
      "Buscando resposta na página: Michel Teló - 13 trechos de texto\n",
      "Número de respostas identificadas: 8\n",
      "Buscando resposta na página: Ángel Di María - 9 trechos de texto\n",
      "Número de respostas identificadas: 8\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('Neymar', 85.02281665802002, 'mogi das cruzes'),\n",
       " ('Neymar', 77.76768684387207, 'mogi das cruzes'),\n",
       " ('Michel Teló', 34.62398338317871, 'medianeira , no parana'),\n",
       " ('Mauricio de Sousa', 20.754725456237793, 'santa isabel , 1935'),\n",
       " ('Michel Teló', 20.021625518798828, 'medianeira')]"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "pergunta = \"Onde Neymar nasceu?\"\n",
    "respondedor.obtem_respostas(pergunta, 5, 5, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Buscando resposta na página: Getúlio Vargas - 32 trechos de texto\n",
      "Número de respostas identificadas: 16\n",
      "Buscando resposta na página: Carta-testamento de Getúlio Vargas - 4 trechos de texto\n",
      "Número de respostas identificadas: 19\n",
      "Buscando resposta na página: Estado Novo (Brasil) - 23 trechos de texto\n",
      "Número de respostas identificadas: 28\n",
      "Buscando resposta na página: Darci Vargas - 6 trechos de texto\n",
      "Número de respostas identificadas: 31\n",
      "Buscando resposta na página: Lutero Vargas - 3 trechos de texto\n",
      "Número de respostas identificadas: 33\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('Getúlio Vargas', 59.90748882293701, 'suicidio'),\n",
       " ('Getúlio Vargas', 43.900707960128784, 'suicidio da mesma forma do pai'),\n",
       " ('Getúlio Vargas', 38.3651864528656, 'suicidio com um tiro no coracao'),\n",
       " ('Getúlio Vargas', 27.303377985954285, 'suicidio'),\n",
       " ('Getúlio Vargas', 22.42054857313633, 'um golpe militar')]"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "pergunta = \"Como morreu Getúlio Vargas?\"\n",
    "respondedor.obtem_respostas(pergunta, 5, 5, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Buscando resposta na página: Independência do Brasil - 12 trechos de texto\n",
      "Número de respostas identificadas: 7\n",
      "Buscando resposta na página: Copa do Brasil de Futebol - 9 trechos de texto\n",
      "Número de respostas identificadas: 9\n",
      "Buscando resposta na página: Proclamação da República do Brasil - 11 trechos de texto\n",
      "Número de respostas identificadas: 11\n",
      "Buscando resposta na página: Guerras de independência na América espanhola - 10 trechos de texto\n",
      "Número de respostas identificadas: 13\n",
      "Buscando resposta na página: Independência ou Morte (Pedro Américo) - 16 trechos de texto\n",
      "Número de respostas identificadas: 17\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('Independência do Brasil', 79.30469036102295, '7 de setembro de 1822'),\n",
       " ('Independência do Brasil', 75.18195152282715, '7 de setembro de 1822'),\n",
       " ('Independência do Brasil', 71.680748462677, '7 de setembro de 1822'),\n",
       " ('Independência do Brasil', 51.37211799621582, '1820'),\n",
       " ('Independência do Brasil', 37.868818044662476, '1821')]"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "pergunta = \"Quando ocorreu a independência do Brasil?\"\n",
    "respondedor.obtem_respostas(pergunta, 5, 5, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Buscando resposta na página: American Bully - 5 trechos de texto\n",
      "Número de respostas identificadas: 2\n",
      "Buscando resposta na página: Dobermann - 5 trechos de texto\n",
      "Número de respostas identificadas: 3\n",
      "Buscando resposta na página: Chihuahua (cão) - 17 trechos de texto\n",
      "Número de respostas identificadas: 7\n",
      "Buscando resposta na página: Yorkshire terrier - 18 trechos de texto\n",
      "Número de respostas identificadas: 11\n",
      "Buscando resposta na página: Fox terrier - 1 trechos de texto\n",
      "Número de respostas identificadas: 12\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('Chihuahua (cão)', 46.28483963012695, '1 a 3 kg'),\n",
       " ('Yorkshire terrier', 27.234413146972656, 'entre 5 e 7 kg'),\n",
       " ('Chihuahua (cão)', 23.80998730659485, '3 kg'),\n",
       " ('Yorkshire terrier',\n",
       "  12.345462799072266,\n",
       "  '9 , 5 cm no comprimento e 7 , 11 cm'),\n",
       " ('Yorkshire terrier', 11.643416166305542, '2 , 3 e os 3 , 5 kg')]"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "pergunta = \"Quanto pesa um cão?\"\n",
    "respondedor.obtem_respostas(pergunta, 5, 5, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Buscando resposta na página: Sonic the Hedgehog - 7 trechos de texto\n",
      "Número de respostas identificadas: 3\n",
      "Buscando resposta na página: Lista de personagens de Sonic the Hedgehog - 12 trechos de texto\n",
      "Número de respostas identificadas: 10\n",
      "Buscando resposta na página: Lista de personagens de Sonic the Hedgehog - 12 trechos de texto\n",
      "Número de respostas identificadas: 17\n",
      "Buscando resposta na página: Sonic - O Filme - 15 trechos de texto\n",
      "Número de respostas identificadas: 21\n",
      "Buscando resposta na página: Sonic the Hedgehog - 7 trechos de texto\n",
      "Número de respostas identificadas: 24\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('Sonic the Hedgehog', 73.69134426116943, 'azul'),\n",
       " ('Sonic the Hedgehog', 58.718299865722656, 'vermelho'),\n",
       " ('Sonic the Hedgehog', 54.86063003540039, 'verde'),\n",
       " ('Lista de personagens de Sonic the Hedgehog', 51.56681251525879, 'roxo'),\n",
       " ('Lista de personagens de Sonic the Hedgehog', 44.35158157348633, 'branca')]"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "pergunta = \"Qual a cor do Sonic?\"\n",
    "respondedor.obtem_respostas(pergunta, 5, 5, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Buscando resposta na página: Guerra Fria - 49 trechos de texto\n",
      "Número de respostas identificadas: 9\n",
      "Buscando resposta na página: Espionagem na Guerra Fria - 4 trechos de texto\n",
      "Número de respostas identificadas: 10\n",
      "Buscando resposta na página: Guerra Fria - 49 trechos de texto\n",
      "Número de respostas identificadas: 19\n",
      "Buscando resposta na página: Guerra Fria - 49 trechos de texto\n",
      "Número de respostas identificadas: 28\n",
      "Buscando resposta na página: Guerra Fria (1947–1953) - 12 trechos de texto\n",
      "Número de respostas identificadas: 31\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('Guerra Fria',\n",
       "  43.41161012649536,\n",
       "  'nao houve combates em larga escala diretamente entre as duas superpotencias'),\n",
       " ('Guerra Fria',\n",
       "  40.61384558677673,\n",
       "  'parecia que qualquer inimigo do regime de bagda era um potencial aliado dos estados unidos'),\n",
       " ('Guerra Fria',\n",
       "  26.046966075897217,\n",
       "  'nao houve combates em larga escala diretamente entre as duas superpotencias'),\n",
       " ('Guerra Fria',\n",
       "  24.36830735206604,\n",
       "  'parecia que qualquer inimigo do regime de bagda era um potencial aliado dos estados unidos'),\n",
       " ('Guerra Fria',\n",
       "  21.05194389820099,\n",
       "  'as tensoes do pos - guerra entre os estados unidos e a uniao sovietica')]"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "pergunta = \"Por que a guerra fria foi fria?\"\n",
    "respondedor.obtem_respostas(pergunta, 5, 5, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}